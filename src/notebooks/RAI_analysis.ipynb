{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbdb75ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "p:\\projects\\heart disease prediction\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Loading and preparing data...\n",
      "‚úÖ Initial preprocessing complete. Shape: (69976, 12)\n",
      "\n",
      "üìä Preparing features for RAI...\n",
      "‚úÖ Final dataset shape: (64976, 12)\n",
      "\n",
      "üìä Class distribution:\n",
      "   Class 0: 32,503 samples (50.0%)\n",
      "   Class 1: 32,473 samples (50.0%)\n",
      "\n",
      "ü§ñ Setting up model...\n",
      "\n",
      "‚öôÔ∏è Training model with tuned XGBoost parameters...\n",
      "\n",
      "üìä Model Performance (Tuned):\n",
      "ROC AUC: 0.7932\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.74      6501\n",
      "           1       0.74      0.69      0.71      6495\n",
      "\n",
      "    accuracy                           0.73     12996\n",
      "   macro avg       0.73      0.73      0.72     12996\n",
      "weighted avg       0.73      0.73      0.72     12996\n",
      "\n",
      "\n",
      "üöÄ Setting up RAI Dashboard...\n",
      "\n",
      "‚öôÔ∏è Computing RAI insights (this may take several minutes)...\n",
      "================================================================================\n",
      "Causal Effects\n",
      "Current Status: Generating Causal Effects.\n",
      "Current Status: Finished generating causal effects.\n",
      "Time taken: 0.0 min 2.2000000171829015e-05 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Counterfactual\n",
      "Time taken: 0.0 min 7.599999662488699e-06 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Error Analysis\n",
      "Current Status: Generating error analysis reports.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"p:\\projects\\heart disease prediction\\env\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 199, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"p:\\projects\\heart disease prediction\\env\\lib\\subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"p:\\projects\\heart disease prediction\\env\\lib\\subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"p:\\projects\\heart disease prediction\\env\\lib\\subprocess.py\", line 1456, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Status: Finished generating error analysis reports.\n",
      "Time taken: 0.0 min 0.30314739999994345 sec\n",
      "================================================================================\n",
      "================================================================================\n",
      "Explanations\n",
      "Current Status: Explaining 11 features\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001067 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 532\n",
      "[LightGBM] [Info] Number of data points in the train set: 51980, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.011971\n",
      "Current Status: Explained 11 features.\n",
      "Time taken: 0.0 min 0.7783541000007972 sec\n",
      "================================================================================\n",
      "\n",
      "üéâ Launching RAI Dashboard...\n",
      "ResponsibleAI started at http://localhost:8704\n",
      "\n",
      "============================================================\n",
      "‚ú® RAI DASHBOARD IS NOW RUNNING ‚ú®\n",
      "============================================================\n",
      "üìä Access the dashboard at: http://localhost:5000\n",
      "üìà Features analyzed: 11\n",
      "üìù Training samples: 51,980\n",
      "üìù Test samples: 12,996\n",
      "============================================================\n",
      "\n",
      "‚ö° Press Ctrl+C to stop the server\n",
      "============================================================\n",
      "\n",
      "\n",
      "üëã Dashboard stopped\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# RAI DASHBOARD - CLINICAL FEATURES ANALYSIS (With Tuned XGBoost)\n",
    "# ==================================================================\n",
    "\n",
    "# --- 1. IMPORTS & CONFIGURATION ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "# RAI imports\n",
    "from responsibleai import RAIInsights\n",
    "from raiwidgets import ResponsibleAIDashboard\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ==================================================================\n",
    "# 1. DATA LOADING & PREPROCESSING\n",
    "# ==================================================================\n",
    "print(\"üîç Loading and preparing data...\")\n",
    "\n",
    "# Setup paths\n",
    "PROJECT_ROOT = Path(os.environ.get('PROJECT_ROOT', '../../')).resolve()\n",
    "DATA_RAW_DIR = Path(os.environ.get('DATA_RAW_DIR', PROJECT_ROOT / 'data/raw')).resolve()\n",
    "data_file = DATA_RAW_DIR / 'heart disease.parquet'\n",
    "\n",
    "# Load dataset\n",
    "if not data_file.is_file():\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_file.resolve()}\")\n",
    "\n",
    "df = pd.read_parquet(data_file)\n",
    "df = df.drop(columns=['id']) if 'id' in df.columns else df\n",
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Column mapping\n",
    "column_mapping = {\n",
    "    'age': 'Age',  \n",
    "    'gender': 'Sex',\n",
    "    'height': 'Height',\n",
    "    'weight': 'Weight',\n",
    "    'ap_hi': 'Systolic_BP',\n",
    "    'ap_lo': 'Diastolic_BP',\n",
    "    'cholesterol': 'Cholesterol_Level',\n",
    "    'gluc': 'Glucose_Level',\n",
    "    'smoke': 'Smoking_Status',\n",
    "    'alco': 'Alcohol_Intake',\n",
    "    'active': 'Physical_Activity',\n",
    "    'cardio': 'target'\n",
    "}\n",
    "df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})\n",
    "\n",
    "# Convert Age from days to years\n",
    "if 'Age' in df.columns:\n",
    "    df['Age_Years'] = (df['Age'] / 365.25).round().astype(int)\n",
    "    df = df.drop(columns=['Age'])\n",
    "\n",
    "# Remove invalid ages\n",
    "df = df[df['Age_Years'].between(0, 100)]\n",
    "\n",
    "# Calculate BMI and drop original columns\n",
    "if 'Height' in df.columns and 'Weight' in df.columns:\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] / 100) ** 2\n",
    "    df = df.drop(columns=['Height', 'Weight'])\n",
    "\n",
    "# Calculate and validate Pulse Pressure\n",
    "if 'Systolic_BP' in df.columns and 'Diastolic_BP' in df.columns:\n",
    "    df['Pulse_Pressure'] = df['Systolic_BP'] - df['Diastolic_BP']\n",
    "    invalid_bp = (df['Pulse_Pressure'] < 20) | (df['Pulse_Pressure'] > 100)\n",
    "    df.loc[invalid_bp, ['Systolic_BP', 'Diastolic_BP', 'Pulse_Pressure']] = np.nan\n",
    "\n",
    "print(f\"‚úÖ Initial preprocessing complete. Shape: {df.shape}\")\n",
    "\n",
    "# ==================================================================\n",
    "# 2. PREPARE RAI FEATURES\n",
    "# ==================================================================\n",
    "print(\"\\nüìä Preparing features for RAI...\")\n",
    "\n",
    "rai_features = [\n",
    "    'Age_Years', 'Sex', 'BMI', \n",
    "    'Systolic_BP', 'Diastolic_BP', 'Pulse_Pressure',\n",
    "    'Cholesterol_Level', 'Glucose_Level',\n",
    "    'Smoking_Status', 'Alcohol_Intake', 'Physical_Activity'\n",
    "]\n",
    "target_col = 'target'\n",
    "MAX_SAMPLES = 5000\n",
    "\n",
    "# Keep only existing features and handle missing values\n",
    "rai_features = [f for f in rai_features if f in df.columns]\n",
    "df_rai = df[rai_features + [target_col]].copy()\n",
    "\n",
    "# Handle missing values\n",
    "for col in df_rai.columns:\n",
    "    if df_rai[col].isna().any():\n",
    "        if df_rai[col].dtype in ['int64', 'float64']:\n",
    "            df_rai[col].fillna(df_rai[col].median(), inplace=True)\n",
    "        else:\n",
    "            df_rai[col].fillna(df_rai[col].mode()[0], inplace=True)\n",
    "\n",
    "# First stratified split to get initial 5000 samples\n",
    "if len(df_rai) > MAX_SAMPLES:\n",
    "    _, df_rai = train_test_split(\n",
    "        df_rai, \n",
    "        train_size=MAX_SAMPLES,\n",
    "        stratify=df_rai[target_col],\n",
    "        random_state=42\n",
    "    )\n",
    "    df_rai = df_rai.reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Final dataset shape: {df_rai.shape}\")\n",
    "print(\"\\nüìä Class distribution:\")\n",
    "class_dist = df_rai[target_col].value_counts()\n",
    "for cls in sorted(class_dist.index):\n",
    "    count = class_dist[cls]\n",
    "    print(f\"   Class {cls}: {count:,} samples ({count/len(df_rai):.1%})\")\n",
    "\n",
    "# ==================================================================\n",
    "# 3. TRAIN/TEST SPLIT & MODEL SETUP\n",
    "# ==================================================================\n",
    "print(\"\\nü§ñ Setting up model...\")\n",
    "\n",
    "X = df_rai[rai_features]\n",
    "y = df_rai[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Define feature types\n",
    "numerical_features = ['Age_Years', 'BMI', 'Systolic_BP', 'Diastolic_BP', 'Pulse_Pressure']\n",
    "ordinal_features = ['Cholesterol_Level', 'Glucose_Level']\n",
    "nominal_features = ['Sex', 'Smoking_Status', 'Alcohol_Intake', 'Physical_Activity']\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', RobustScaler(), numerical_features),\n",
    "    ('ord', OrdinalEncoder(categories=[[1, 2, 3]] * 2), ordinal_features),\n",
    "    ('nom', OneHotEncoder(drop='first', sparse=False), nominal_features)\n",
    "], remainder='drop')\n",
    "\n",
    "# Best XGBoost parameters (from Optuna)\n",
    "best_params = {\n",
    "    'n_estimators': 422,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.06439748935039273,\n",
    "    'subsample': 0.7224788588671935,\n",
    "    'colsample_bytree': 0.6288331170227341,\n",
    "    'random_state': 42,\n",
    "    'use_label_encoder': False,\n",
    "    'eval_metric': 'logloss'\n",
    "}\n",
    "\n",
    "# Pipeline with SMOTE and tuned XGBoost\n",
    "pipeline = ImbPipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('balancer', SMOTE(random_state=42)),\n",
    "    ('classifier', XGBClassifier(**best_params))\n",
    "])\n",
    "\n",
    "# Train model\n",
    "print(\"\\n‚öôÔ∏è Training model with tuned XGBoost parameters...\")\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\nüìä Model Performance (Tuned):\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ==================================================================\n",
    "# 4. RAI DASHBOARD SETUP\n",
    "# ==================================================================\n",
    "print(\"\\nüöÄ Setting up RAI Dashboard...\")\n",
    "\n",
    "train_with_target = X_train.copy()\n",
    "train_with_target[target_col] = y_train\n",
    "test_with_target = X_test.copy()\n",
    "test_with_target[target_col] = y_test\n",
    "\n",
    "rai_insights = RAIInsights(\n",
    "    model=pipeline,\n",
    "    train=train_with_target,\n",
    "    test=test_with_target,\n",
    "    target_column=target_col,\n",
    "    task_type='classification',\n",
    "    categorical_features=ordinal_features + nominal_features\n",
    ")\n",
    "\n",
    "# Add explainer and error analysis\n",
    "rai_insights.explainer.add()\n",
    "rai_insights.error_analysis.add()\n",
    "\n",
    "# Compute insights\n",
    "print(\"\\n‚öôÔ∏è Computing RAI insights (this may take several minutes)...\")\n",
    "rai_insights.compute()\n",
    "\n",
    "# Launch dashboard\n",
    "print(\"\\nüéâ Launching RAI Dashboard...\")\n",
    "ResponsibleAIDashboard(rai_insights)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ú® RAI DASHBOARD IS NOW RUNNING ‚ú®\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìä Access the dashboard at: http://localhost:5000\")\n",
    "print(f\"üìà Features analyzed: {len(rai_features)}\")\n",
    "print(f\"üìù Training samples: {len(X_train):,}\")\n",
    "print(f\"üìù Test samples: {len(X_test):,}\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚ö° Press Ctrl+C to stop the server\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Keep notebook running\n",
    "try:\n",
    "    import time\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n\\nüëã Dashboard stopped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2159e6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ú® Creating PROPER mutually exclusive features...\n",
      "‚úÖ Proper mutually exclusive features created.\n",
      "\n",
      "==================================================\n",
      "MUTUAL EXCLUSIVITY VERIFICATION\n",
      "==================================================\n",
      "\n",
      "1. Sedentary Elderly Cases: 6009\n",
      "   Physical_Activity_mod values in these cases:\n",
      "   NaN    6009\n",
      "Name: Physical_Activity_mod, dtype: int64\n",
      "\n",
      "2. PreHtn_NormalChol Cases: 30754\n",
      "   Cholesterol_Level_mod values in these cases:\n",
      "   NaN    30754\n",
      "Name: Cholesterol_Level_mod, dtype: int64\n",
      "\n",
      "3. Cases with double-counting (should be 0): 0\n",
      "\n",
      "============================================================\n",
      "RUNNING CORRECTED MUTUAL EXCLUSIVITY ANALYSIS\n",
      "============================================================\n",
      "\n",
      "--- BEFORE New Features ---\n",
      "Subgroup size: 481\n",
      "Error Rate: 37.63%\n",
      "\n",
      "--- AFTER New Features (Mutually Exclusive) ---\n",
      "Subgroup size: 481\n",
      "Error Rate: 36.80%\n",
      "\n",
      "Mutual Exclusivity Impact:\n",
      "  - 481/481 cases captured by 'Sedentary_Elderly'\n",
      "  - 352/481 cases captured by 'PreHtn_NormalChol'\n",
      "  - Physical_Activity_mod values for sedentary cases: [-999.]\n"
     ]
    }
   ],
   "source": [
    "# Import TomekLinks\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "# ==================================================================\n",
    "# 2. CORRECT MUTUALLY EXCLUSIVE FEATURE CREATION\n",
    "# ==================================================================\n",
    "\n",
    "print(\"\\n‚ú® Creating PROPER mutually exclusive features...\")\n",
    "\n",
    "df_after = df.copy()\n",
    "\n",
    "# 1. For \"Sedentary Elderly\" - Physical Activity == 0 should be EXCLUDED from original\n",
    "df_after['Sedentary_Elderly'] = (\n",
    "    (df_after['Age_Years'] > 55) & (df_after['Physical_Activity'] == 0)\n",
    ").astype(int)\n",
    "\n",
    "# Create modified physical activity where class 0 is EXCLUDED/REMOVED\n",
    "df_after['Physical_Activity_mod'] = df_after['Physical_Activity'].copy()\n",
    "# Remove the specific class (0) that went into the new feature\n",
    "df_after.loc[df_after['Sedentary_Elderly'] == 1, 'Physical_Activity_mod'] = np.nan\n",
    "# Option: Remove entirely or create a new category like 'excluded_sedentary'\n",
    "\n",
    "# 2. For \"Pre-Hypertension with Normal Cholesterol\" - Cholesterol_Level == 1 should be EXCLUDED\n",
    "df_after['PreHtn_NormalChol'] = (\n",
    "    (df_after['Systolic_BP'].between(120, 139)) & (df_after['Cholesterol_Level'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# Create modified cholesterol where class 1 is EXCLUDED/REMOVED  \n",
    "df_after['Cholesterol_Level_mod'] = df_after['Cholesterol_Level'].copy()\n",
    "df_after.loc[df_after['PreHtn_NormalChol'] == 1, 'Cholesterol_Level_mod'] = np.nan\n",
    "\n",
    "print(\"‚úÖ Proper mutually exclusive features created.\")\n",
    "\n",
    "# ==================================================================\n",
    "# 3. VERIFICATION OF MUTUAL EXCLUSIVITY\n",
    "# ==================================================================\n",
    "\n",
    "def verify_mutual_exclusivity(df_after):\n",
    "    \"\"\"Verify that the mutual exclusivity logic is working correctly\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"MUTUAL EXCLUSIVITY VERIFICATION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Check 1: Sedentary Elderly vs Physical_Activity_mod\n",
    "    sedentary_cases = df_after[df_after['Sedentary_Elderly'] == 1]\n",
    "    print(f\"\\n1. Sedentary Elderly Cases: {len(sedentary_cases)}\")\n",
    "    print(\"   Physical_Activity_mod values in these cases:\")\n",
    "    print(f\"   {sedentary_cases['Physical_Activity_mod'].value_counts(dropna=False)}\")\n",
    "    \n",
    "    # Check 2: PreHtn_NormalChol vs Cholesterol_Level_mod\n",
    "    prehtn_cases = df_after[df_after['PreHtn_NormalChol'] == 1]\n",
    "    print(f\"\\n2. PreHtn_NormalChol Cases: {len(prehtn_cases)}\")\n",
    "    print(\"   Cholesterol_Level_mod values in these cases:\")\n",
    "    print(f\"   {prehtn_cases['Cholesterol_Level_mod'].value_counts(dropna=False)}\")\n",
    "    \n",
    "    # Check 3: Verify no double-counting\n",
    "    overlapping = df_after[\n",
    "        (df_after['Sedentary_Elderly'] == 1) & \n",
    "        (df_after['Physical_Activity_mod'] == 0)\n",
    "    ]\n",
    "    print(f\"\\n3. Cases with double-counting (should be 0): {len(overlapping)}\")\n",
    "\n",
    "verify_mutual_exclusivity(df_after)\n",
    "\n",
    "# ==================================================================\n",
    "# 4. UPDATED ERROR ANALYSIS WITH CORRECT SUBGROUP DEFINITION\n",
    "# ==================================================================\n",
    "\n",
    "def run_error_analysis_corrected(X, y, description, original_df, use_modified_features=False):\n",
    "    \"\"\"Trains a model with CORRECT mutual exclusivity logic.\"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    # Handle NaN values created by mutual exclusivity\n",
    "    if use_modified_features:\n",
    "        X_train = X_train.fillna(-999)  # Special value for excluded cases\n",
    "        X_test = X_test.fillna(-999)\n",
    "\n",
    "    # Preprocessing setup\n",
    "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
    "    categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Handle modified features\n",
    "    modified_features = ['Physical_Activity_mod', 'Cholesterol_Level_mod']\n",
    "    for f in modified_features:\n",
    "        if f in X.columns:\n",
    "            if f in numerical_features:\n",
    "                numerical_features.remove(f)\n",
    "            if f not in categorical_features:\n",
    "                categorical_features.append(f)\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', RobustScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse=False, handle_unknown='ignore'), categorical_features)\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "    pipeline = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('balancer', TomekLinks()),\n",
    "        ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    results_df = X_test.copy()\n",
    "    results_df['true_label'] = y_test\n",
    "    results_df['predicted_label'] = y_pred\n",
    "    \n",
    "    # Join with original data for consistent subgroup definition\n",
    "    # Use the index to join and add _orig suffix for original features\n",
    "    original_cols = ['Cholesterol_Level', 'Physical_Activity', 'Age_Years']\n",
    "    for col in original_cols:\n",
    "        if col in original_df.columns:\n",
    "            results_df[f'{col}_orig'] = original_df.loc[results_df.index, col]\n",
    "\n",
    "    # Define subgroup using ORIGINAL features (consistent definition)\n",
    "    subgroup = results_df[\n",
    "        (results_df['Systolic_BP'] <= 139.5) &\n",
    "        (results_df['Age_Years_orig'] > 57.5) &\n",
    "        (results_df['Cholesterol_Level_orig'] != 3) &\n",
    "        (results_df['BMI'] > 21.97) &\n",
    "        (results_df['Physical_Activity_orig'] == 0)\n",
    "    ]\n",
    "    \n",
    "    if len(subgroup) == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Subgroup for '{description}' is empty. Cannot calculate error rate.\")\n",
    "        return\n",
    "\n",
    "    errors = (subgroup['true_label'] != subgroup['predicted_label']).sum()\n",
    "    error_rate = errors / len(subgroup)\n",
    "    \n",
    "    print(f\"\\n--- {description} ---\")\n",
    "    print(f\"Subgroup size: {len(subgroup)}\")\n",
    "    print(f\"Error Rate: {error_rate:.2%}\")\n",
    "    \n",
    "    # Show mutual exclusivity impact\n",
    "    if use_modified_features:\n",
    "        print(f\"\\nMutual Exclusivity Impact:\")\n",
    "        sedentary_in_subgroup = subgroup['Sedentary_Elderly'].sum()\n",
    "        prehtn_in_subgroup = subgroup['PreHtn_NormalChol'].sum()\n",
    "        \n",
    "        print(f\"  - {sedentary_in_subgroup}/{len(subgroup)} cases captured by 'Sedentary_Elderly'\")\n",
    "        print(f\"  - {prehtn_in_subgroup}/{len(subgroup)} cases captured by 'PreHtn_NormalChol'\")\n",
    "        \n",
    "        # Show what happened to the original features for these cases\n",
    "        if sedentary_in_subgroup > 0:\n",
    "            sedentary_cases = subgroup[subgroup['Sedentary_Elderly'] == 1]\n",
    "            unique_vals = sedentary_cases['Physical_Activity_mod'].unique()\n",
    "            print(f\"  - Physical_Activity_mod values for sedentary cases: {unique_vals}\")\n",
    "\n",
    "# Run analyses\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RUNNING CORRECTED MUTUAL EXCLUSIVITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# BEFORE analysis (original features)\n",
    "base_features = [\n",
    "    'Age_Years', 'Sex', 'BMI', 'Systolic_BP', 'Diastolic_BP', 'Pulse_Pressure',\n",
    "    'Cholesterol_Level', 'Glucose_Level', 'Smoking_Status', 'Alcohol_Intake', 'Physical_Activity'\n",
    "]\n",
    "X_before = df[base_features]\n",
    "y_before = df['target']\n",
    "run_error_analysis_corrected(X_before, y_before, \"BEFORE New Features\", df, False)\n",
    "\n",
    "# AFTER analysis with PROPER mutually exclusive features\n",
    "extended_features = [\n",
    "    'Age_Years', 'Sex', 'BMI', 'Systolic_BP', 'Diastolic_BP', 'Pulse_Pressure',\n",
    "    'Glucose_Level', 'Smoking_Status', 'Alcohol_Intake',\n",
    "    'Physical_Activity_mod', 'Cholesterol_Level_mod',  # Modified originals\n",
    "    'PreHtn_NormalChol', 'Sedentary_Elderly', 'Age_Weighted_BMI'  # New features\n",
    "]\n",
    "extended_features = [col for col in extended_features if col in df_after.columns]\n",
    "\n",
    "X_after = df_after[extended_features]\n",
    "y_after = df_after['target']\n",
    "run_error_analysis_corrected(X_after, y_after, \"AFTER New Features (Mutually Exclusive)\", df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1029a90a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
